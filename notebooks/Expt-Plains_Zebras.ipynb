{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set global utool flags\n",
    "import utool as ut\n",
    "ut.util_io.__PRINT_WRITES__ = False\n",
    "ut.util_io.__PRINT_READS__ = False\n",
    "ut.util_parallel.__FORCE_SERIAL__ = True\n",
    "ut.util_cache.VERBOSE_CACHE = False\n",
    "ut.NOT_QUIET = False\n",
    "\n",
    "# Matplotlib stuff\n",
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "# Define database for this test run\n",
    "import ibeis\n",
    "db = 'PZ_Master1'\n",
    "#db = 'GZ_ALL'\n",
    "#db = 'NNP_MasterGIRM_core'\n",
    " \n",
    "# Setup database specific configs\n",
    "if db == 'PZ_MTEST' or db == 'GZ_ALL':\n",
    "    seperability_annot_cfgs = ['ctrl']\n",
    "else:\n",
    "    seperability_annot_cfgs = ['timequalctrl']\n",
    "\n",
    "if db == 'PZ_Master1':\n",
    "    varysize = ['varysize_pzm']\n",
    "    varypername = ['varypername_pzm']\n",
    "elif db == 'GZ_ALL':\n",
    "    varysize = ['varysize_gz']\n",
    "    varypername = ['varypername_gz']\n",
    "elif db == 'NNP_MasterGIRM_core':\n",
    "    varysize = ['varysize_girm']\n",
    "    varypername = ['varypername_girm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_result = ibeis.run_experiment(\n",
    "    e='rank_cdf', \n",
    "    db=db, \n",
    "    a=['unctrl', 'ctrl::unctrl:qpername=1,qview_ext=0'],\n",
    "    t=['baseline'])\n",
    "#test_result.print_unique_annot_config_stats()\n",
    "_ = test_result.draw_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Baseline Timedeltas FP\n",
    "test_result = ibeis.run_experiment(\n",
    "    e='timedelta_hist',\n",
    "    db=db, \n",
    "    a=['ctrl::unctrl:qpername=1,qview_ext=0'], \n",
    "    t=['baseline'],\n",
    "    truepos=True)\n",
    "test_result.draw_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Baseline Timedeltas FP\n",
    "test_result = ibeis.run_experiment(\n",
    "    e='timedelta_hist',\n",
    "    db=db, \n",
    "    a=['ctrl::unctrl:qpername=1,qview_ext=0'], \n",
    "    t=['baseline'],\n",
    "    falsepos=True)\n",
    "test_result.draw_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Time Experiment \n",
    "test_result = ibeis.run_experiment(\n",
    "    e='rank_cdf',\n",
    "    db=db, \n",
    "    a=['largetimedelta', 'ctrl'], \n",
    "    t=['baseline'])\n",
    "test_result.draw_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Timedelta PIE for new False Pos \n",
    "test_result = ibeis.run_experiment(\n",
    "    e='timedelta_hist',\n",
    "    db=db, \n",
    "    a=['largetimedelta'], \n",
    "    t=['baseline'],\n",
    "    falsepos=True)\n",
    "test_result.draw_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Size Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# K Experiment \n",
    "test_result = ibeis.run_experiment(\n",
    "    e='rank_surface',\n",
    "    db=db, \n",
    "    a=varysize, \n",
    "    t=['candidacy_k'])\n",
    "#test_result.print_unique_annot_config_stats()\n",
    "test_result.draw_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring Mechanism Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Namescore Experiment\n",
    "test_result = ibeis.run_experiment(\n",
    "    e='rank_cdf',\n",
    "    db=db, \n",
    "    a=varypername, \n",
    "    t=['candidacy_namescore'])\n",
    "test_result.draw_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewpoint Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    test_result = ibeis.run_experiment(\n",
    "        e='rank_cdf',\n",
    "        db=db, \n",
    "        a=['viewpoint_compare'], \n",
    "        t=['baseline'])\n",
    "    test_result.draw_func()\n",
    "except AssertionError as ex:\n",
    "    ut.printex(ex, 'Database does not support this test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invariance Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_result = ibeis.run_experiment(\n",
    "    e='rank_cdf',\n",
    "    db=db, \n",
    "    a=['ctrl'], \n",
    "    t=['candidacy_invariance'])\n",
    "test_result.draw_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Invariance + Viewpoint Experiment\n",
    "try:\n",
    "    test_result = ibeis.run_experiment(\n",
    "        e='rank_cdf',\n",
    "        db=db, \n",
    "        a=['viewpoint_compare'], \n",
    "        t=['candidacy_invariance'], \n",
    "        test_cfgx_slice=slice(6, None))\n",
    "    test_result.draw_func()\n",
    "except AssertionError as ex:\n",
    "    ut.printex(ex, 'Database does not support this test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Invariance + Time Experiment\n",
    "test_result = ibeis.run_experiment(\n",
    "    e='rank_cdf',\n",
    "    db=db, \n",
    "    a=['timectrl'], \n",
    "    t=['baseline:AQH=False,AI=True',\n",
    "       'baseline:AQH=True,AI=False',\n",
    "       'baseline:AQH=False,AI=False'])\n",
    "_ = test_result.draw_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Invariance + Time Experiment\n",
    "test_result = ibeis.run_experiment(\n",
    "    e='rank_cdf',\n",
    "    db=db, \n",
    "    a=seperability_annot_cfgs, \n",
    "    t=['baseline:AQH=False,AI=True',\n",
    "       'baseline:AQH=True,AI=False',\n",
    "       'baseline:AQH=False,AI=False'])\n",
    "_ = test_result.draw_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Score Seperability Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Score Seperability of Good Cases\n",
    "test_result = ibeis.run_experiment(\n",
    "    e='scores',\n",
    "    db=db, \n",
    "    a=seperability_annot_cfgs, \n",
    "    t=['invarbest'],\n",
    "    f=[':fail=False,min_gf_timedelta=None'],\n",
    ")\n",
    "_ = test_result.draw_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Score Seperability with NO FILTERING\n",
    "test_result = ibeis.run_experiment(\n",
    "    e='scores',\n",
    "    db=db, \n",
    "    a=seperability_annot_cfgs, \n",
    "    t=['invarbest'],\n",
    "    f=[':fail=None,min_gf_timedelta=None']\n",
    ")\n",
    "_ = test_result.draw_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_result = ibeis.run_experiment(\n",
    "    e='taghist',\n",
    "    db=db, \n",
    "    a=seperability_annot_cfgs, \n",
    "    t=['invarbest'],\n",
    "    f=[':fail=None,min_gf_timedelta=None']\n",
    ")\n",
    "_ = test_result.draw_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Success cases with large timedelta for groundfalse cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Score Seperability of Good Cases where large timedelta gf are gone\n",
    "test_result = ibeis.run_experiment(\n",
    "    e='scores',\n",
    "    db=db, \n",
    "    a=seperability_annot_cfgs, \n",
    "    t=['invarbest'],\n",
    "    f=[':fail=False,min_gf_timedelta=12h']\n",
    ")\n",
    "_ = test_result.draw_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All cases with large timedelta for groundfalse cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Score Seperability of \n",
    "test_result = ibeis.run_experiment(\n",
    "    e='scores',\n",
    "    db=db, \n",
    "    a=seperability_annot_cfgs, \n",
    "    t=['baseline:AQH=True,AI=False'],\n",
    "    f=[':fail=None,min_gf_timedelta=12h']\n",
    ") \n",
    "_ = test_result.draw_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Investigate the reasons for the high scoring groundfalse cases\n",
    "test_result = ibeis.run_experiment(\n",
    "    e='taghist',\n",
    "    db=db, \n",
    "    a=['timecontrolled'], \n",
    "    t=['invarbest'],\n",
    "    f=[':fail=None,min_gf_timedelta=12h']\n",
    ")\n",
    "_ = test_result.draw_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

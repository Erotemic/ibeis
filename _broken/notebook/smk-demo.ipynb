{
 "metadata": {
  "name": "",
  "signature": "sha256:7140a70f7388d6b301b1c48ca35f587cce3419d746ddfd90be590296b0f3a348"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import ibeis\n",
      "import six\n",
      "import vtool\n",
      "import utool\n",
      "import numpy as np\n",
      "import numpy.linalg as npl  # NOQA\n",
      "import pandas as pd\n",
      "np.set_printoptions(precision=2)\n",
      "pd.set_option('display.max_rows', 10)\n",
      "pd.set_option('display.max_columns', 10)\n",
      "pd.set_option('isplay.notebook_repr_html', True)\n",
      "ibeis.ensure_pz_mtest()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "have mtest_dir='F:/data/work/PZ_MTEST'\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_annot_df(ibs):\n",
      "    aid_list = ibs.get_valid_aids()\n",
      "    _kpts_col = pd.DataFrame(ibs.get_annot_kpts(aid_list),\n",
      "                             index=aid_list, columns=['kpts'])\n",
      "    _vecs_col = pd.DataFrame(ibs.get_annot_desc(aid_list),\n",
      "                             index=aid_list, columns=['vecs'])\n",
      "    annots_df = pd.concat([_vecs_col, _kpts_col], axis=1)\n",
      "    return annots_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def learn_visual_words(annots_df, train_aids, nCentroids):\n",
      "    from vtool import clustering2 as clustertool\n",
      "    clustertool.rrr()\n",
      "    vecs_list = annots_df['vecs'][train_aids].as_matrix()\n",
      "    train_vecs = np.vstack(vecs_list)\n",
      "    print('Training %d word vocabulary with %d annots and %d descriptors' %\n",
      "          (nCentroids, len(train_aids), len(train_vecs)))\n",
      "    words = clustertool.precompute_akmeans(train_vecs, nCentroids, max_iters=100)\n",
      "    return words"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "def index_data_annots(annots_df, daids, words):\n",
      "    from vtool import nearest_neighbors as nntool\n",
      "    vecs_list = annots_df['vecs'][daids]\n",
      "    flann_params = {}\n",
      "    wordflann = vtool.nearest_neighbors.flann_cache(words, flann_params=flann_params)\n",
      "    idx2_vec, idx2_ax, idx2_fx = nntool.invertable_stack(vecs_list, daids)\n",
      "    ax2_aid = np.array(daids)\n",
      "    wx2_idxs = inverted_assignments(wordflann, idx2_vec)\n",
      "    print('Vectors per word')\n",
      "    print(utool.stats_str(map(len, wx2_idxs)))\n",
      "    invindex = InvertedIndex(words, wordflann, idx2_vec, idx2_ax, idx2_fx, ax2_aid)\n",
      "    return invindex\n",
      "\n",
      "\n",
      "def inverted_assignments(wordflann, idx2_vec):\n",
      "    idx2_wx, _idx2_wdist = wordflann.nn_index(idx2_vec, 1)\n",
      "    idx_list = list(range(len(idx2_wx)))\n",
      "    # TODO: replace with pandas groupby\n",
      "    wx2_idxs_dict = utool.group_items(idx_list, idx2_wx.tolist())\n",
      "    wx2_idxs = wx2_idxs_dict.values()\n",
      "    return wx2_idxs\n",
      "\n",
      "\n",
      "@six.add_metaclass(utool.ReloadingMetaclass)\n",
      "class InvertedIndex(object):\n",
      "    def __init__(invindex, words, wordflann, idx2_vec, idx2_ax, idx2_fx, ax2_aid):\n",
      "        invindex.wordflann = wordflann\n",
      "        invindex.words     = words\n",
      "        invindex.ax2_aid   = ax2_aid\n",
      "        invindex.idx2_vec  = idx2_vec\n",
      "        invindex.idx2_ax   = idx2_ax\n",
      "        invindex.idx2_fx   = idx2_fx\n",
      "        invindex.wx2_idxs = invindex.inverted_assignments(idx2_vec)\n",
      "\n",
      "    def inverted_assignments(invindex, idx2_vec):\n",
      "        return inverted_assignments(invindex.wordflann, idx2_vec)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def main():\n",
      "    ibs = ibeis.opendb('PZ_MTEST')\n",
      "    annots_df = make_annot_df(ibs)\n",
      "    valid_aids = annots_df.index\n",
      "    # Training set\n",
      "    train_aids = valid_aids[0:20:2]\n",
      "    # Database set\n",
      "    daids  = valid_aids[3::2]\n",
      "    # Search set\n",
      "    qaids = valid_aids[0::2]\n",
      "    nCentroids = 10\n",
      "    words = learn_visual_words(annots_df, train_aids, nCentroids)\n",
      "    invindex = index_data_annots(annots_df, daids, words)\n",
      "    return locals()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "main_locals = main()\n",
      "main_execstr = utool.execstr_dict(main_locals, 'main_locals')\n",
      "exec(main_execstr)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[ibs._init_dirs] ibs.dbdir = 'F:\\\\data\\\\work\\\\PZ_MTEST'\n",
        "[ensure_correct_version] Database version: u'1.0.1' | Expected version: '1.0.1' "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ibs] building default config\n",
        "RELOAD: [clustering2] __name__=vtool.clustering2"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Training 10 word vocabulary with 10 annots and 10676 descriptors\n",
        "[akmeans] pre_akmeans()\n",
        "Warning: no cache dir specified\n",
        "[cache] * load_cPkl('akmeans_centroids_FLANN()_DPTS((10676,128)%0dytztceyvefc3w).cPkl', data)\n",
        "[akmeans.precompute] load successful\n",
        "Warning: no cache dir specified\n",
        "...flann_cache cfgstr = '_FLANN()_DPTS((10,128)a1+9sr9@npqz+38u)': \n",
        "...flann cache hit\n",
        "{'max': 6739.0, 'min': 4796.0, 'mean': 5892.3, 'std': 585.318, 'nMin': 1, 'nMax': 1, 'shape': (10,)}"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 15
    }
   ],
   "metadata": {}
  }
 ]
}
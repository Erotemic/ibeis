{
 "metadata": {
  "name": "",
  "signature": "sha256:8d8e79e55c7e816433e742564ccfbb7a29742e2a045d36480c1877bc09bfdce0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import ibeis\n",
      "import vtool\n",
      "import utool\n",
      "import numpy as np\n",
      "import numpy.linalg as npl\n",
      "np.set_printoptions(precision=2)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ibeis.ensure_pz_mtest()\n",
      "ibs = ibeis.opendb('PZ_MTEST')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "have mtest_dir='F:/data/work/PZ_MTEST'\n",
        "[ibs._init_dirs] ibs.dbdir = 'F:\\\\data\\\\work\\\\PZ_MTEST'\n",
        "[ensure_correct_version] Database version: u'1.0.1' | Expected version: '1.0.1' "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[ibs] building default config\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "taids = ibs.get_valid_aids()\n",
      "tvecs_list = ibs.get_annot_desc(taids)\n",
      "tvec_list = np.vstack(tvecs_list)\n",
      "print(len(tvecs_list))\n",
      "print(len(tvec_list))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "119\n",
        "120590\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#import pyflann\n",
      "#flann = pyflann.FLANN()\n",
      "#help(flann.kmeans)\n",
      "#centroids = flann.kmeans(tvec_list, num_clusters=1000, max_iterations=100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels, words = vtool.clustering.precompute_akmeans(tvec_list, 1000, 30, cache_dir='.')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[akmeans] pre_akmeans()\n",
        "[cache] * load_cPkl('akmeans_clusters_FLANN()_DPTS((120590,128)0&q+ina20q33dfii).cPkl', data)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[cache] * load_cPkl('akmeans_datax2cl_FLANN()_DPTS((120590,128)0&q+ina20q33dfii).cPkl', data)\n",
        "[akmeans.precompute] load successful\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(words.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(1000, 128)\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "help(vtool.nearest_neighbors.flann_cache)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Help on function flann_cache in module vtool.nearest_neighbors:\n",
        "\n",
        "flann_cache(dpts, cache_dir=None, cfgstr='', flann_params=None, use_cache=True, save=True, use_params_hash=True, use_data_hash=True)\n",
        "    Tries to load a cached flann index before doing anything\n",
        "    from vtool.nn\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "help(vtool.clustering.precompute_akmeans)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Help on function precompute_akmeans in module vtool.clustering:\n",
        "\n",
        "precompute_akmeans(data, num_clusters, max_iters=5, flann_params={}, cache_dir=None, force_recomp=False, use_data_hash=True, cfgstr='', refine=False, akmeans_cfgstr=None)\n",
        "    precompute aproximate kmeans with builtin caching\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "centroid_flann = vtool.nearest_neighbors.flann_cache(words, cache_dir='.', flann_params={})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "...flann_cache cfgstr = '_FLANN()_DPTS((1000,128)f6rp+s93u4pl72o7)': \n",
        "...flann cache hit\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "indexes, dists = centroid_flann.nn_index(tvec_list, 1) \n",
      "print(indexes.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(120590,)\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "wx2_tvec = utool.group_items(tvec_list.tolist(), indexes.tolist())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "word_index = list(wx2_tvec.keys())[0]\n",
      "vecs = np.array(wx2_tvec[word_index], dtype=np.float64)\n",
      "word = np.array(words[word_index], dtype=np.float64)\n",
      "residuals = np.array([word - vec for vec in vecs])\n",
      "residuals_n = vtool.linalg.normalize_rows(residuals)\n",
      "#print(vecs)\n",
      "#print(residuals)\n",
      "print(residuals_n)\n",
      "print(residuals_n.shape)\n",
      "print((residuals_n ** 2).sum(-1))\n",
      "#print(word)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.14  0.06  0.04 ..., -0.01  0.06  0.06]\n",
        " [ 0.15  0.06  0.04 ...,  0.03  0.01 -0.09]\n",
        " [ 0.15  0.06  0.03 ...,  0.02 -0.18  0.02]\n",
        " ..., \n",
        " [-0.25 -0.15  0.03 ...,  0.    0.02  0.06]\n",
        " [-0.3   0.07  0.04 ..., -0.01  0.02 -0.05]\n",
        " [-0.25  0.03  0.03 ...,  0.03  0.07  0.05]]\n",
        "(93, 128)\n",
        "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
        "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
        "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
        "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
        "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
        "  1.  1.  1.]\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Compare each residual vec to all others in this word index\n",
      "rvecs = residuals_n\n",
      "similarity_matrix = (rvecs.dot(rvecs.T))\n",
      "print(similarity_matrix)\n",
      "print(similarity_matrix.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 1.    0.24 -0.12 ..., -0.18 -0.03 -0.1 ]\n",
        " [ 0.24  1.   -0.01 ..., -0.35  0.4  -0.1 ]\n",
        " [-0.12 -0.01  1.   ..., -0.01 -0.29  0.01]\n",
        " ..., \n",
        " [-0.18 -0.35 -0.01 ...,  1.   -0.06 -0.03]\n",
        " [-0.03  0.4  -0.29 ..., -0.06  1.    0.38]\n",
        " [-0.1  -0.1   0.01 ..., -0.03  0.38  1.  ]]\n",
        "(93, 93)\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas\n",
      "pandas.set_option('display.max_rows', 10)  \n",
      "pandas.set_option('display.max_columns', 10)  \n",
      "tvecs_list = ibs.get_annot_desc(taids)\n",
      "idx2_vec, idx2_ax, idx2_fx = vtool.nearest_neighbors.invertable_stack(tvecs_list, taids) \n",
      "print(idx2_vec)\n",
      "#print(pandas.DataFrame(residuals_n))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 19   0   0 ..., 106   4   0]\n",
        " [ 58   0   0 ...,  26   4   1]\n",
        " [ 10  40  55 ...,   9  27  54]\n",
        " ..., \n",
        " [  1  12  43 ...,   1   1  19]\n",
        " [ 10  16  16 ...,   3  32  90]\n",
        " [  0   0   0 ...,   0   0   0]]\n"
       ]
      }
     ],
     "prompt_number": 76
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tvecdf_list = [pandas.DataFrame(vecs) for vecs in tvecs_list]\n",
      "print('A single images descriptors')\n",
      "print(tvecdf_list[0])\n",
      "tvecs_df = pandas.DataFrame(tvecdf_list, index=taids)\n",
      "print('All images descriptors')\n",
      "print(tvecs_df)\n",
      "print('Stacked descriptors')\n",
      "\n",
      "print(tvecs_df.stack(0))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "A single images descriptors\n",
        "      0    1    2    3    4   ...   123  124  125  126  127\n",
        "0      19    0    0    1    3 ...     0   12  106    4    0\n",
        "1      58    0    0    2    2 ...    11   38   26    4    1\n",
        "2      10   40   55   37   10 ...     0    0    9   27   54\n",
        "3      71    6    0    0    1 ...     1    3    0    0    0\n",
        "4       0    0    3    2   82 ...     4    3    0    0   26\n",
        "...   ...  ...  ...  ...  ... ...   ...  ...  ...  ...  ...\n",
        "1070    8   14    6   11   14 ...    29   46   15    7   15\n",
        "1071   23   17    3   19   48 ...     4    7    5   13   52\n",
        "1072   78    0    0    0    0 ...    11   56    7    5    8\n",
        "1073   40   24    2   12   42 ...    25   19    3    0    5\n",
        "1074   59    7    5    2    0 ...     1   21   70   33   15\n",
        "\n",
        "[1075 rows x 128 columns]\n",
        "All images descriptors\n",
        "                                                     0\n",
        "1          0    1    2    3    4   ...   123  124  ...\n",
        "2          0    1    2    3    4   ...   123  124  ...\n",
        "3         0    1    2    3    4   ...   123  124  1...\n",
        "4          0    1    2    3    4   ...   123  124  ...\n",
        "5         0    1    2    3    4   ...   123  124  1...\n",
        "..                                                 ...\n",
        "115       0    1    2    3    4   ...   123  124  1...\n",
        "116       0    1    2    3    4   ...   123  124  1...\n",
        "117       0    1    2    3    4   ...   123  124  1...\n",
        "118        0    1    2    3    4   ...   123  124  ...\n",
        "119       0    1    2    3    4   ...   123  124  1...\n",
        "\n",
        "[119 rows x 1 columns]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Stacked descriptors\n",
        "1  0          0    1    2    3    4   ...   123  124  ...\n",
        "2  0          0    1    2    3    4   ...   123  124  ...\n",
        "3  0         0    1    2    3    4   ...   123  124  1...\n",
        "...\n",
        "117  0         0    1    2    3    4   ...   123  124  1...\n",
        "118  0          0    1    2    3    4   ...   123  124  ...\n",
        "119  0         0    1    2    3    4   ...   123  124  1...\n",
        "Length: 119, dtype: object\n"
       ]
      }
     ],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}